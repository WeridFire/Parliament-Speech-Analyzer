{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üèõÔ∏è Italian Parliament Speech Analyzer\n",
        "\n",
        "This notebook runs the complete analysis pipeline for Italian Parliament speeches.\n",
        "\n",
        "## What this notebook does:\n",
        "1. **Scrapes** speeches from senato.it and camera.it\n",
        "2. **Generates embeddings** using Sentence Transformers\n",
        "3. **Computes analytics** (identity, relations, temporal, sentiment)\n",
        "4. **Exports JSON** files for the frontend visualization\n",
        "\n",
        "---\n",
        "\n",
        "‚ö†Ô∏è **GPU Recommended**: Enable GPU runtime for faster embedding generation.\n",
        "\n",
        "`Runtime ‚Üí Change runtime type ‚Üí T4 GPU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clone_repo",
        "outputId": "098f4f85-f667-469c-cea8-70d771f460e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Parliament-Speech-Analyzer' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/WeridFire/Parliament-Speech-Analyzer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "install_deps",
        "outputId": "89a35dfe-0bbb-4989-e509-e4d84bf05464",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Parliament-Speech-Analyzer'\n",
            "/content/Parliament-Speech-Analyzer\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (4.13.5)\n",
            "Collecting SPARQLWrapper>=2.0.0 (from -r requirements.txt (line 13))\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (5.2.0)\n",
            "Requirement already satisfied: spacy>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (3.8.11)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (4.57.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (2.9.0+cu126)\n",
            "Requirement already satisfied: plotly>=5.18.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (5.24.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r requirements.txt (line 11)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r requirements.txt (line 11)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r requirements.txt (line 11)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r requirements.txt (line 11)) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 12)) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 12)) (4.15.0)\n",
            "Collecting rdflib>=6.1.1 (from SPARQLWrapper>=2.0.0->-r requirements.txt (line 13))\n",
            "  Downloading rdflib-7.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 16)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 16)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.2.0->-r requirements.txt (line 17)) (0.36.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.5.0->-r requirements.txt (line 20)) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 24)) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 24)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 24)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 24)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 24)) (0.7.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (3.6.1)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 25)) (3.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.18.0->-r requirements.txt (line 28)) (9.1.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.0->-r requirements.txt (line 17)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->-r requirements.txt (line 20)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->-r requirements.txt (line 20)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->-r requirements.txt (line 20)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from rdflib>=6.1.1->SPARQLWrapper>=2.0.0->-r requirements.txt (line 13)) (3.2.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 25)) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.5.0->-r requirements.txt (line 20)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.5.0->-r requirements.txt (line 20)) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.5.0->-r requirements.txt (line 20)) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.5.0->-r requirements.txt (line 20)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.5.0->-r requirements.txt (line 20)) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy>=3.5.0->-r requirements.txt (line 20)) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.5.0->-r requirements.txt (line 20)) (2.0.1)\n",
            "Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading rdflib-7.5.0-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m587.2/587.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0 rdflib-7.5.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "‚úÖ Core dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install Python dependencies\n",
        "%cd /content/Parliament-Speech-Analyzer\n",
        "!pip install -r requirements.txt\n",
        "# Install spaCy for advanced keyword extraction\n",
        "!pip install -q spacy\n",
        "!python -m spacy download it_core_news_sm -q\n",
        "\n",
        "print(\"‚úÖ Core dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "optional_transformers"
      },
      "outputs": [],
      "source": [
        "# Optional: Install transformer sentiment (more accurate, takes longer)\n",
        "# Comment the line below if you don't want to use --transformer-sentiment\n",
        "\n",
        "!pip install -q transformers torch\n",
        "\n",
        "USE_TRANSFORMER_SENTIMENT = True  # Set to True if you installed transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_header"
      },
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Choose your data source and analysis settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATA_SOURCE = \"both\"  # Options: \"senate\", \"camera\", \"both\"\n",
        "FORCE_REFETCH = False  # Set to True to re-scrape from parliament websites\n",
        "FORCE_REEMBED = False  # Set to True to regenerate embeddings\n",
        "\n",
        "print(f\"üìã Configuration:\")\n",
        "print(f\"   Data source: {DATA_SOURCE}\")\n",
        "print(f\"   Force refetch: {FORCE_REFETCH}\")\n",
        "print(f\"   Force reembed: {FORCE_REEMBED}\")\n",
        "print(f\"   Transformer sentiment: {USE_TRANSFORMER_SENTIMENT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_header"
      },
      "source": [
        "## 3. Run the Analysis Pipeline\n",
        "\n",
        "This step:\n",
        "- Scrapes speeches (first run takes ~10-15 minutes)\n",
        "- Generates embeddings (~5 min with GPU, ~15 min CPU)\n",
        "- Computes all analytics\n",
        "- Exports JSON files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_pipeline"
      },
      "outputs": [],
      "source": [
        "# Build the command\n",
        "cmd = f\"python backend/export_data.py --source {DATA_SOURCE}\"\n",
        "\n",
        "if FORCE_REFETCH:\n",
        "    cmd += \" --refetch\"\n",
        "if FORCE_REEMBED:\n",
        "    cmd += \" --reembed\"\n",
        "if USE_TRANSFORMER_SENTIMENT:\n",
        "    cmd += \" --transformer-sentiment\"\n",
        "\n",
        "print(f\"üöÄ Running: {cmd}\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Run the pipeline\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verify_header"
      },
      "source": [
        "## 4. Verify Output\n",
        "\n",
        "Check that the JSON files were generated successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify_output"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "output_dir = \"frontend/public\"\n",
        "files = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
        "\n",
        "print(\"üìÅ Generated files:\")\n",
        "for f in files:\n",
        "    path = os.path.join(output_dir, f)\n",
        "    size_mb = os.path.getsize(path) / (1024 * 1024)\n",
        "\n",
        "    # Load and show stats\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    n_speeches = len(data.get('speeches', []))\n",
        "    n_deputies = len(data.get('deputies', []))\n",
        "\n",
        "    print(f\"   ‚úÖ {f}: {size_mb:.2f} MB | {n_speeches} speeches | {n_deputies} deputies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_header"
      },
      "source": [
        "## 5. Download Results\n",
        "\n",
        "Download the generated JSON files to use with the frontend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_files"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Create a zip of all output files\n",
        "!cd frontend/public && zip -r ../../parliament_data.zip *.json\n",
        "\n",
        "# Download the zip\n",
        "files.download('parliament_data.zip')\n",
        "\n",
        "print(\"\\nüì• Download started! Extract the zip and place files in frontend/public/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "explore_header"
      },
      "source": [
        "## 6. Quick Data Exploration\n",
        "\n",
        "Preview some analytics results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_analytics"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load one of the output files\n",
        "with open('frontend/public/camera.json', 'r', encoding='utf-8') as f:\n",
        "    camera_data = json.load(f)\n",
        "\n",
        "# Show available analytics\n",
        "analytics = camera_data.get('analytics', {}).get('global', {})\n",
        "print(\"üìä Available Analytics:\")\n",
        "for key in analytics.keys():\n",
        "    print(f\"   - {key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_keywords"
      },
      "outputs": [],
      "source": [
        "# Example: Show distinctive keywords for a party\n",
        "identity = analytics.get('identity', {})\n",
        "keywords = identity.get('distinctive_keywords', {})\n",
        "\n",
        "print(\"\\nüè∑Ô∏è Distinctive Keywords by Party:\")\n",
        "for party, words in list(keywords.items())[:5]:  # First 5 parties\n",
        "    print(f\"\\n   {party}:\")\n",
        "    print(f\"   {', '.join(words[:10])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_affinity"
      },
      "outputs": [],
      "source": [
        "# Example: Show party affinity matrix\n",
        "relations = analytics.get('relations', {})\n",
        "affinity = relations.get('affinity_matrix', {})\n",
        "\n",
        "if affinity:\n",
        "    print(\"\\nü§ù Top Party Pairs by Semantic Similarity:\")\n",
        "    pairs = affinity.get('pairs', [])[:10]\n",
        "    for p in pairs:\n",
        "        print(f\"   {p['party1']} ‚Üî {p['party2']}: {p['similarity']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Download** `parliament_data.zip` from Step 5\n",
        "2. **Extract** the JSON files to your local `frontend/public/` folder\n",
        "3. **Run the frontend** locally:\n",
        "   ```bash\n",
        "   cd frontend\n",
        "   npm install\n",
        "   npm run dev\n",
        "   ```\n",
        "4. **Open** `http://localhost:5173` in your browser\n",
        "\n",
        "---\n",
        "\n",
        "Made with ‚ù§Ô∏è for political science research"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}