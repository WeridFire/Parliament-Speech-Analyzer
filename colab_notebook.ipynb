{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "intro"
            },
            "source": [
                "# üèõÔ∏è Italian Parliament Speech Analyzer\n",
                "\n",
                "This notebook runs the complete analysis pipeline for Italian Parliament speeches.\n",
                "\n",
                "## What this notebook does:\n",
                "1. **Scrapes** speeches from senato.it and camera.it\n",
                "2. **Generates embeddings** using Sentence Transformers\n",
                "3. **Computes analytics** (identity, relations, temporal, sentiment)\n",
                "4. **Exports JSON** files for the frontend visualization\n",
                "\n",
                "---\n",
                "\n",
                "‚ö†Ô∏è **GPU Recommended**: Enable GPU runtime for faster embedding generation.\n",
                "\n",
                "`Runtime ‚Üí Change runtime type ‚Üí T4 GPU`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_header"
            },
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/YOUR_USERNAME/politics.git\n",
                "%cd politics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "# Install Python dependencies\n",
                "!pip install -r requirements.txt\n",
                "# Install spaCy for advanced keyword extraction\n",
                "!pip install -q spacy\n",
                "!python -m spacy download it_core_news_sm -q\n",
                "\n",
                "print(\"‚úÖ Core dependencies installed!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "optional_transformers"
            },
            "outputs": [],
            "source": [
                "# Optional: Install transformer sentiment (more accurate, takes longer)\n",
                "# Comment the line below if you don't want to use --transformer-sentiment\n",
                "\n",
                "!pip install -q transformers torch\n",
                "\n",
                "USE_TRANSFORMER_SENTIMENT = True  # Set to True if you installed transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config_header"
            },
            "source": [
                "## 2. Configuration\n",
                "\n",
                "Choose your data source and analysis settings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config"
            },
            "outputs": [],
            "source": [
                "# Configuration\n",
                "DATA_SOURCE = \"both\"  # Options: \"senate\", \"camera\", \"both\"\n",
                "FORCE_REFETCH = False  # Set to True to re-scrape from parliament websites\n",
                "FORCE_REEMBED = False  # Set to True to regenerate embeddings\n",
                "\n",
                "print(f\"üìã Configuration:\")\n",
                "print(f\"   Data source: {DATA_SOURCE}\")\n",
                "print(f\"   Force refetch: {FORCE_REFETCH}\")\n",
                "print(f\"   Force reembed: {FORCE_REEMBED}\")\n",
                "print(f\"   Transformer sentiment: {USE_TRANSFORMER_SENTIMENT}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "run_header"
            },
            "source": [
                "## 3. Run the Analysis Pipeline\n",
                "\n",
                "This step:\n",
                "- Scrapes speeches (first run takes ~10-15 minutes)\n",
                "- Generates embeddings (~5 min with GPU, ~15 min CPU)\n",
                "- Computes all analytics\n",
                "- Exports JSON files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_pipeline"
            },
            "outputs": [],
            "source": [
                "# Build the command\n",
                "cmd = f\"python backend/export_data.py --source {DATA_SOURCE}\"\n",
                "\n",
                "if FORCE_REFETCH:\n",
                "    cmd += \" --refetch\"\n",
                "if FORCE_REEMBED:\n",
                "    cmd += \" --reembed\"\n",
                "if USE_TRANSFORMER_SENTIMENT:\n",
                "    cmd += \" --transformer-sentiment\"\n",
                "\n",
                "print(f\"üöÄ Running: {cmd}\\n\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Run the pipeline\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "verify_header"
            },
            "source": [
                "## 4. Verify Output\n",
                "\n",
                "Check that the JSON files were generated successfully."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "verify_output"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "\n",
                "output_dir = \"frontend/public\"\n",
                "files = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
                "\n",
                "print(\"üìÅ Generated files:\")\n",
                "for f in files:\n",
                "    path = os.path.join(output_dir, f)\n",
                "    size_mb = os.path.getsize(path) / (1024 * 1024)\n",
                "    \n",
                "    # Load and show stats\n",
                "    with open(path, 'r', encoding='utf-8') as file:\n",
                "        data = json.load(file)\n",
                "    \n",
                "    n_speeches = len(data.get('speeches', []))\n",
                "    n_deputies = len(data.get('deputies', []))\n",
                "    \n",
                "    print(f\"   ‚úÖ {f}: {size_mb:.2f} MB | {n_speeches} speeches | {n_deputies} deputies\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download_header"
            },
            "source": [
                "## 5. Download Results\n",
                "\n",
                "Download the generated JSON files to use with the frontend."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_files"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Create a zip of all output files\n",
                "!cd frontend/public && zip -r ../../parliament_data.zip *.json\n",
                "\n",
                "# Download the zip\n",
                "files.download('parliament_data.zip')\n",
                "\n",
                "print(\"\\nüì• Download started! Extract the zip and place files in frontend/public/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "explore_header"
            },
            "source": [
                "## 6. Quick Data Exploration\n",
                "\n",
                "Preview some analytics results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "explore_analytics"
            },
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "# Load one of the output files\n",
                "with open('frontend/public/camera.json', 'r', encoding='utf-8') as f:\n",
                "    camera_data = json.load(f)\n",
                "\n",
                "# Show available analytics\n",
                "analytics = camera_data.get('analytics', {}).get('global', {})\n",
                "print(\"üìä Available Analytics:\")\n",
                "for key in analytics.keys():\n",
                "    print(f\"   - {key}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "show_keywords"
            },
            "outputs": [],
            "source": [
                "# Example: Show distinctive keywords for a party\n",
                "identity = analytics.get('identity', {})\n",
                "keywords = identity.get('distinctive_keywords', {})\n",
                "\n",
                "print(\"\\nüè∑Ô∏è Distinctive Keywords by Party:\")\n",
                "for party, words in list(keywords.items())[:5]:  # First 5 parties\n",
                "    print(f\"\\n   {party}:\")\n",
                "    print(f\"   {', '.join(words[:10])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "show_affinity"
            },
            "outputs": [],
            "source": [
                "# Example: Show party affinity matrix\n",
                "relations = analytics.get('relations', {})\n",
                "affinity = relations.get('affinity_matrix', {})\n",
                "\n",
                "if affinity:\n",
                "    print(\"\\nü§ù Top Party Pairs by Semantic Similarity:\")\n",
                "    pairs = affinity.get('pairs', [])[:10]\n",
                "    for p in pairs:\n",
                "        print(f\"   {p['party1']} ‚Üî {p['party2']}: {p['similarity']:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "next_steps"
            },
            "source": [
                "---\n",
                "\n",
                "## Next Steps\n",
                "\n",
                "1. **Download** `parliament_data.zip` from Step 5\n",
                "2. **Extract** the JSON files to your local `frontend/public/` folder\n",
                "3. **Run the frontend** locally:\n",
                "   ```bash\n",
                "   cd frontend\n",
                "   npm install\n",
                "   npm run dev\n",
                "   ```\n",
                "4. **Open** `http://localhost:5173` in your browser\n",
                "\n",
                "---\n",
                "\n",
                "Made with ‚ù§Ô∏è for political science research"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
