{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "intro"
            },
            "source": [
                "# üèõÔ∏è Italian Parliament Speech Analyzer\n",
                "\n",
                "This notebook runs the complete analysis pipeline for Italian Parliament speeches.\n",
                "\n",
                "## What this notebook does:\n",
                "1. **Scrapes** speeches from senato.it and camera.it\n",
                "2. **Generates embeddings** using Sentence Transformers\n",
                "3. **Computes analytics** (identity, relations, temporal, sentiment)\n",
                "4. **Exports JSON** files for the frontend visualization\n",
                "\n",
                "---\n",
                "\n",
                "‚ö†Ô∏è **GPU Recommended**: `Runtime ‚Üí Change runtime type ‚Üí T4 GPU`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_header"
            },
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "suppress_warnings"
            },
            "outputs": [],
            "source": [
                "# Suppress TensorFlow and other noisy warnings\n",
                "import os\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'\n",
                "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print('‚úÖ Warnings suppressed')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/WeridFire/Parliament-Speech-Analyzer.git\n",
                "%cd Parliament-Speech-Analyzer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "# Install dependencies (don't install torch - use Colab's pre-installed version)\n",
                "!pip install -q pandas numpy requests beautifulsoup4 SPARQLWrapper\n",
                "!pip install -q scikit-learn sentence-transformers plotly tqdm\n",
                "!pip install -q spacy transformers\n",
                "!python -m spacy download it_core_news_sm -q\n",
                "\n",
                "print('‚úÖ All dependencies installed!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config_header"
            },
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config"
            },
            "outputs": [],
            "source": [
                "# Configuration\n",
                "DATA_SOURCE = 'both'  # Options: 'senate', 'camera', 'both'\n",
                "USE_TRANSFORMER_SENTIMENT = True  # True for better accuracy, False for speed\n",
                "\n",
                "print(f'üìã Data source: {DATA_SOURCE}')\n",
                "print(f'üìã Transformer sentiment: {USE_TRANSFORMER_SENTIMENT}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "run_header"
            },
            "source": [
                "## 3. Run Analysis Pipeline\n",
                "\n",
                "This will:\n",
                "- Scrape speeches (~10-15 min first run)\n",
                "- Generate embeddings (~5 min GPU)\n",
                "- Compute all analytics\n",
                "- Export JSON files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_pipeline"
            },
            "outputs": [],
            "source": [
                "# Build and run command\n",
                "# Use -u to force unbuffered output so we see logs in real-time\n",
                "cmd = f'python -u backend/export_data.py --source {DATA_SOURCE} --refetch --reembed --verbose'\n",
                "if USE_TRANSFORMER_SENTIMENT:\n",
                "    cmd += ' --transformer-sentiment'\n",
                "\n",
                "print(f'üöÄ Running: {cmd}')\n",
                "print('=' * 60)\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "verify_header"
            },
            "source": [
                "## 4. Verify Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "verify_output"
            },
            "outputs": [],
            "source": [
                "import os, json\n",
                "\n",
                "output_dir = 'frontend/public'\n",
                "files = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
                "\n",
                "print('üìÅ Generated files:')\n",
                "for f in files:\n",
                "    path = os.path.join(output_dir, f)\n",
                "    size_mb = os.path.getsize(path) / (1024 * 1024)\n",
                "    with open(path, 'r', encoding='utf-8') as file:\n",
                "        data = json.load(file)\n",
                "    print(f'   ‚úÖ {f}: {size_mb:.2f} MB | {len(data.get(\"speeches\", []))} speeches')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download_header"
            },
            "source": [
                "## 5. Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_files"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "!cd frontend/public && zip -r ../../parliament_data.zip *.json\n",
                "files.download('parliament_data.zip')\n",
                "\n",
                "print('\\nüì• Download complete! Extract to frontend/public/')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "explore_header"
            },
            "source": [
                "## 6. Quick Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "explore"
            },
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "with open('frontend/public/camera.json', 'r', encoding='utf-8') as f:\n",
                "    data = json.load(f)\n",
                "\n",
                "analytics = data.get('analytics', {}).get('global', {})\n",
                "print('üìä Available Analytics:', list(analytics.keys()))\n",
                "\n",
                "# Show sample keywords\n",
                "keywords = analytics.get('identity', {}).get('distinctive_keywords', {})\n",
                "for party, words in list(keywords.items())[:3]:\n",
                "    print(f'\\nüè∑Ô∏è {party}: {', '.join(words[:8])}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "next_steps"
            },
            "source": [
                "---\n",
                "## Next Steps\n",
                "\n",
                "1. Download `parliament_data.zip`\n",
                "2. Extract to `frontend/public/`\n",
                "3. Run frontend: `cd frontend && npm install && npm run dev`\n",
                "4. Open http://localhost:5173"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
